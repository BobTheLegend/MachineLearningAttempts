{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from celluloid import Camera\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_ANSWER = 9999\n",
    "TRAIN_DATA_LOC = \"C:\\\\Users\\\\17Z990\\\\Downloads\\\\Repos\\\\MachineLearningAttempts\\\\TrainingData\\\\mnist_train.csv\"\n",
    "TEST_DATA_LOC = \"C:\\\\Users\\\\17Z990\\\\Downloads\\\\Repos\\\\MachineLearningAttempts\\\\TrainingData\\\\mnist_test.csv\"\n",
    "VALID_DATA_LOC = \"C:\\\\Users\\\\17Z990\\\\Downloads\\\\Repos\\\\MachineLearningAttempts\\\\TrainingData\\\\mnist_valid.csv\"\n",
    "OG_TRAIN_DATA_LOC = \"C:\\\\Users\\\\17Z990\\\\Downloads\\\\Repos\\\\MachineLearningAttempts\\\\TrainingData\\\\OG_mnist_train.csv\"\n",
    "LAYERS = [784,16,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got the original csv version of the MNIST database here:\n",
    "https://pjreddie.com/projects/mnist-in-csv/\n",
    "and then I seperated the training portion into a validation portion and a new training portion using this code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = openCSV(OG_TRAIN_DATA_LOC)\n",
    "with open(VALID_DATA_LOC,'w', newline = '') as validData:\n",
    "    validWriter = csv.writer(validData)\n",
    "    for i in range(10000):\n",
    "        validWriter.writerow(trainData[i])\n",
    "with open(TRAIN_DATA_LOC,'w',newline = '') as newData:\n",
    "    newWriter = csv.writer(newData)\n",
    "    for i in range(50000):\n",
    "        newWriter.writerow(trainData[i + 10000])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where all the Data is initially handled and all the functions pertaining to it. The data was seperated for use into 3 different csv files for each type of data. train_mnist.csv is the training data containing 50,000 examples, test_mnist.csv is the testing data containing 10,000 examples, and mnist_valid.csv is the validation data used to derive hyper-parameters and it contains 10,000 examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openCSV(dataLocation):\n",
    "    file = open(dataLocation,'r')\n",
    "    dataReader = csv.reader(file)\n",
    "    file = []\n",
    "    for row in dataReader:\n",
    "        file.append(row)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMNISTData(dataLocation):\n",
    "    mnistData = []\n",
    "    with open(dataLocation,'r') as data:\n",
    "        dataReader = csv.reader(data)\n",
    "        for row in dataReader:\n",
    "            ans = row.pop(0)\n",
    "            img = row\n",
    "            \n",
    "            mnistData.append((img,ans))\n",
    "    return mnistData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes a list/array which is 785 or 784 ints long depending on whether an answer is present\n",
    "#Takes a boolean stating whether answers are present are at the beginning (assumes true)\n",
    "def showData(numArray, answerPresent=True):\n",
    "    if type(numArray) != list and type(numArray) != np.ndarray:\n",
    "        raise ValueError(\"The numArray parameter is the wrong value. Try again with either a list or array\")\n",
    "    if type(answerPresent) != bool:\n",
    "        raise ValueError(\"The answerPresent parameter is the wrong value. Try again with a boolean\")\n",
    "    if answerPresent:\n",
    "        if len(numArray) != 785:\n",
    "            raise IndexError(\"Your array is bigger than allowed. Try checking the answerPresent parameter\")\n",
    "    if not answerPresent:\n",
    "        if len(numArray) != 784:\n",
    "            raise IndexError(\"Your array is bigger than allowed. Try checking the answerPresent parameter\")\n",
    "    \n",
    "    if answerPresent:\n",
    "        ans = numArray[0]\n",
    "        imgArray = numArray[1:]\n",
    "    else:\n",
    "        imgArray = numArray\n",
    "        ans = NO_ANSWER\n",
    "        \n",
    "    for i in range(len(imgArray)):\n",
    "        imgArray[i] = float(imgArray[i])\n",
    "        showArray = np.array(imgArray).reshape(28,28)\n",
    "    plt.imshow(showArray,'gray')\n",
    "    plt.show()\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the supporting functions for the neural net class that are universal enough to exist outside it. In addition is a function that generates noise to possibly feed into the neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dervSigmoid(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genRandData():\n",
    "    randData = np.random.choice(256,784) #Makes a random array with a length of 784 with numbers between 0 and 255\n",
    "    randData = np.concatenate(([NO_ANSWER],randData))\n",
    "    return randData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the class for the neural net that will hopefully make the network simple to use. It is the bare bones approach to machine learning but it will be improved, expanded and duplicated in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(object):\n",
    "    def __init__(self,layers):\n",
    "        self.numLayers = len(layers)\n",
    "        #Creates 1 bias for every neuron in the layers after input\n",
    "        self.biases = [np.random.randn(b,1) for b in layers[1:]]\n",
    "        #Creates weights for every other weight connected to it\n",
    "        self.weights = [np.random.randn(y,x) for x,y in zip(layers[:-1],layers[1:])]\n",
    "    \n",
    "    def costFunc(self,netAns,targetAns):\n",
    "        x = np.subtract(targetAns,netAns)\n",
    "        topArray = np.square(x)\n",
    "        cost = np.divide(topArray,2)\n",
    "        return cost\n",
    "    \n",
    "    def dervCostFunc(self,netAns,targetAns):\n",
    "        return(netAns - targetAns)\n",
    "\n",
    "    def feedForward(self,a):\n",
    "        for b,w in zip(self.biases,self.weights):\n",
    "            a = sigmoid(np.dot(w,a) + b)\n",
    "        return a\n",
    "    \n",
    "    def backProp(self, x, y):\n",
    "        biasesDerv = [np.zeros(b.shape) for b in self.biases]\n",
    "        weightsDerv = [np.zeros(w.shape) for w in self.weights]\n",
    "        a = np.array(x).astype('float64')\n",
    "        activations = [a]\n",
    "        zList = [] #List storing the z's \n",
    "        #Basically doing feedforward but noting the z's \n",
    "        #Could be combined with feedforward function in future\n",
    "        for w,b in zip(self.weights,self.biases):\n",
    "            z = np.dot(w,a) + b\n",
    "            zList.append(z)\n",
    "            a = sigmoid(z)\n",
    "            activations.append(a)\n",
    "            \n",
    "        #Calculating the error for the first layer\n",
    "\n",
    "        error = self.dervCostFunc(activations[-1],float(y)) * dervSigmoid(zList[-1])\n",
    "        biasesDerv[-1] = error \n",
    "        weightsDerv[-1] = np.dot(error,activations[-2].transpose())\n",
    "        \n",
    "        #Doing the backpropogation stuff\n",
    "        for i in range(2,self.numLayers):\n",
    "            z = zList[-i]\n",
    "            w = self.weights[-i + 1].transpose()\n",
    "            error = np.dot(w,error) * dervSigmoid(z)\n",
    "            biasesDerv[-i] = error\n",
    "            weightsDerv[-i] = np.dot(error,activations[-i - 1].transpose())\n",
    "        \n",
    "        return(biasesDerv,weightsDerv)\n",
    "    \n",
    "    #Runs the gradient descent algorithm for a small part of the data called an batch which makes up 1 epoch\n",
    "    def runBatch(self,epoch,learnRate):\n",
    "        deltaB = [np.zeros(b.shape) for b in self.biases]\n",
    "        deltaW = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x,y in epoch:\n",
    "            singDeltB,singDeltW = self.backProp(x,y)\n",
    "            deltaB = [db + sdb for db,sdb in zip(deltaB,singDeltB)]\n",
    "            deltaW = [dw + sdw for dw,sdw in zip(deltaW,singDeltW)]\n",
    "        self.weights = [w - ((learnRate * len(epoch)) * dw) for w,dw in zip(self.weights,deltaW)]\n",
    "        self.biases = [b - ((learnRate * len(epoch)) * db) for b,db in zip(self.biases,deltaB)]\n",
    "        \n",
    "        \n",
    "    def testNet(self,testData):\n",
    "        testResults = [(np.argmax(self.feedForward(x)),y) for x,y in testData]\n",
    "        return sum(int(x == y) for x,y in testResults)\n",
    "        \n",
    "    \n",
    "    def stocGradientDescent(self,trainingData,epochs,batchSize,learnRate,testData = None):\n",
    "        if testData:\n",
    "            numTest = len(testData)\n",
    "        numTrain = len(trainingData)\n",
    "        \n",
    "        for ex in range(epochs):\n",
    "            random.shuffle(trainingData)\n",
    "            batches = [trainingData[k:k + batchSize] for k in range(0,numTrain,batchSize)]\n",
    "            for batch in batches:\n",
    "                self.runBatch(batch,learnRate)\n",
    "            if testData:\n",
    "                print(\"Epoch {0}: {1} / {2}\".format(i,self.testNet(),numTest))\n",
    "            else:\n",
    "                print(\"Epoch {0} complete\").format(i)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = getMNISTData(TRAIN_DATA_LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = getMNISTData(TEST_DATA_LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (16,16) and (784,) not aligned: 16 (dim 1) != 784 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-993960907636>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstocGradientDescent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtestData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-ab24e984fee9>\u001b[0m in \u001b[0;36mstocGradientDescent\u001b[1;34m(self, trainingData, epochs, batchSize, learnRate, testData)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mbatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumTrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearnRate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtestData\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch {0}: {1} / {2}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtestNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumTest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-ab24e984fee9>\u001b[0m in \u001b[0;36mrunBatch\u001b[1;34m(self, epoch, learnRate)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mdeltaW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0msingDeltB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msingDeltW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackProp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[0mdeltaB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msdb\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msdb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeltaB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msingDeltB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdeltaW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdw\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msdw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msdw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeltaW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msingDeltW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-ab24e984fee9>\u001b[0m in \u001b[0;36mbackProp\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdervSigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mbiasesDerv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mweightsDerv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbiasesDerv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweightsDerv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (16,16) and (784,) not aligned: 16 (dim 1) != 784 (dim 0)"
     ]
    }
   ],
   "source": [
    "net.stocGradientDescent(trainData, 30, 10, 3.0, testData=testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
